{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing libraries\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting some importating global variables and constants\n",
    "ROOT_FOLDER_TRAINING = \"data_set/Training\"\n",
    "ROOT_FOLDER_TEST = \"data_set/Test\"\n",
    "\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Renaming the folder names to lowercase and replacing the spaces for underscore(_)\n",
    "def rename_folders(root_folder):\n",
    "    for subdir, dirs, _ in os.walk(root_folder, topdown=False):\n",
    "        for dir_name in dirs:\n",
    "            new_dir_name = dir_name.replace(\" \", \"_\").replace(\"-\", \"_\").lower()  # Add more replacements if needed\n",
    "            old_dir_path = os.path.join(subdir, dir_name)\n",
    "            new_dir_path = os.path.join(subdir, new_dir_name)\n",
    "            if old_dir_path != new_dir_path:\n",
    "                os.rename(old_dir_path, new_dir_path)\n",
    "\n",
    "rename_folders(ROOT_FOLDER_TRAINING)\n",
    "rename_folders(ROOT_FOLDER_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting the classes names\n",
    "def classes(root_folder):\n",
    "    classes = set()\n",
    "    for subdir, dirs, _ in os.walk(root_folder):\n",
    "        for dir_name in dirs:\n",
    "            classes.add(dir_name.lower())\n",
    "    return classes\n",
    "\n",
    "classes = classes(ROOT_FOLDER_TRAINING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the images from folders\n",
    "def load_images_from_folder(root_folder):\n",
    "    images = []\n",
    "    for i in classes:\n",
    "        path = os.path.join(root_folder, i)\n",
    "        class_num = list(classes).index(i)\n",
    "\n",
    "        for img in os.listdir(path):\n",
    "            if img.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "                img_array = cv2.imread(os.path.join(path, img))\n",
    "                img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                images.append([img_array, class_num])\n",
    "    return images\n",
    "\n",
    "images_training = load_images_from_folder(ROOT_FOLDER_TRAINING)\n",
    "images_test = load_images_from_folder(ROOT_FOLDER_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the trainining and test arrays\n",
    "random.shuffle(images_training)\n",
    "random.shuffle(images_test)\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "def create_arrays_for_cnn(img_array, feature_array, class_array):\n",
    "    for features, label in img_array:\n",
    "        feature_array.append(features)\n",
    "        class_array.append(label)\n",
    "\n",
    "create_arrays_for_cnn(images_training, X_train, Y_train)\n",
    "create_arrays_for_cnn(images_test, X_test, Y_test)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Converting classes to categorial form\n",
    "Y_train = to_categorical(Y_train, num_classes = 141)\n",
    "Y_test = to_categorical(Y_test, num_classes = 141)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizing the images\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split valdiation and train set\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=8, kernel_size=(3, 3), padding=\"Same\", activation=\"relu\", input_shape=(100, 100, 3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.35))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), padding=\"Same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.35))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"Same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(141, activation=\"softmax\"))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False\n",
    ")\n",
    "\n",
    "# Assuming x_train and y_train are defined\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Model fitting using `fit` method\n",
    "history = model.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(x_val, y_val),\n",
    "    steps_per_epoch=x_train.shape[0] // BATCH_SIZE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
